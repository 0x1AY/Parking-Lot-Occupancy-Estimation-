{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b6c9bcce",
      "metadata": {
        "id": "b6c9bcce"
      },
      "source": [
        "# Parking Lot Occupancy Estimation - Training\n",
        "\n",
        "This notebook trains deep learning models for parking lot occupancy estimation.\n",
        "\n",
        "**Authors:** Aminu Yiwere, Olatunji Olagundoye\n",
        "**Date:** November 5, 2025  \n",
        "**Environment:** Google Colab\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d9776d1",
      "metadata": {
        "id": "3d9776d1"
      },
      "source": [
        "## 1. Setup and Installation\n",
        "\n",
        "Install required packages and mount Google Drive (if using Colab)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b11f1db6",
      "metadata": {
        "id": "b11f1db6"
      },
      "outputs": [],
      "source": [
        "# Check if running on Colab and mount Google Drive\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "yygSItkcl44L",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yygSItkcl44L",
        "outputId": "a3d9d266-9a4d-4ad1-80cd-e7e593ad7a41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "H7tioam5mDan",
      "metadata": {
        "id": "H7tioam5mDan"
      },
      "outputs": [],
      "source": [
        "dataset_url = '/content/drive/MyDrive/Car Park.v6-final-dataset1.yolov11'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d39c0adc",
      "metadata": {
        "id": "d39c0adc"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82b8a6e6",
      "metadata": {
        "id": "82b8a6e6"
      },
      "source": [
        "## 2. Import Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cce7e58e",
      "metadata": {
        "id": "cce7e58e"
      },
      "outputs": [],
      "source": [
        "# Import all necessary libraries\n",
        "import os\n",
        "import yaml\n",
        "from ultralytics import YOLO\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0358033",
      "metadata": {
        "id": "b0358033"
      },
      "source": [
        "## 3. Configuration and Hyperparameters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd1eac50",
      "metadata": {
        "id": "dd1eac50"
      },
      "outputs": [],
      "source": [
        "# Define configuration and hyperparameters\n",
        "config = {\n",
        "    'dataset_path': dataset_url,  # Path to dataset\n",
        "    'data_yaml': os.path.join(dataset_url, 'data.yaml'),  # Path to data.yaml\n",
        "    'model_name': 'yolov11n.pt',  # YOLOv11 nano (options: yolov11n, yolov11s, yolov11m)\n",
        "    'epochs': 100,\n",
        "    'batch_size': 16,\n",
        "    'img_size': 640,\n",
        "    'patience': 20,  # Early stopping patience\n",
        "    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
        "    'project': 'parking_lot_detection',\n",
        "    'name': 'yolov11n_training',\n",
        "    'save_dir': '/content/drive/MyDrive/parking_results'\n",
        "}\n",
        "\n",
        "print(f\"Configuration:\")\n",
        "print(f\"  Device: {config['device']}\")\n",
        "print(f\"  Model: {config['model_name']}\")\n",
        "print(f\"  Epochs: {config['epochs']}\")\n",
        "print(f\"  Batch Size: {config['batch_size']}\")\n",
        "print(f\"  Image Size: {config['img_size']}\")\n",
        "print(f\"  Dataset: {config['dataset_path']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9874cef",
      "metadata": {
        "id": "a9874cef"
      },
      "source": [
        "## 4. Dataset Class and Data Augmentation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56bc7e1f",
      "metadata": {
        "id": "56bc7e1f"
      },
      "outputs": [],
      "source": [
        "# YOLOv11 handles dataset loading internally\n",
        "# No need to define custom dataset class - YOLO uses the data.yaml configuration\n",
        "print(\"Dataset will be loaded automatically by YOLO using data.yaml\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aebfb230",
      "metadata": {
        "id": "aebfb230"
      },
      "outputs": [],
      "source": [
        "# YOLOv11 includes built-in augmentations\n",
        "# Augmentation parameters are configured in the training call\n",
        "print(\"Augmentation settings will be applied during training\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35b7a0aa",
      "metadata": {
        "id": "35b7a0aa"
      },
      "source": [
        "## 5. Load and Explore Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38432e20",
      "metadata": {
        "id": "38432e20"
      },
      "outputs": [],
      "source": [
        "# Verify dataset structure and data.yaml\n",
        "print(\"Verifying dataset structure...\")\n",
        "print(f\"\\nDataset path exists: {os.path.exists(config['dataset_path'])}\")\n",
        "print(f\"data.yaml exists: {os.path.exists(config['data_yaml'])}\")\n",
        "\n",
        "# List directory contents\n",
        "if os.path.exists(config['dataset_path']):\n",
        "    print(f\"\\nDataset contents:\")\n",
        "    for item in os.listdir(config['dataset_path']):\n",
        "        item_path = os.path.join(config['dataset_path'], item)\n",
        "        if os.path.isdir(item_path):\n",
        "            num_files = len(os.listdir(item_path)) if os.path.exists(item_path) else 0\n",
        "            print(f\"  {item}/ ({num_files} items)\")\n",
        "        else:\n",
        "            print(f\"  {item}\")\n",
        "\n",
        "# Read and display data.yaml\n",
        "if os.path.exists(config['data_yaml']):\n",
        "    print(\"\\ndata.yaml contents:\")\n",
        "    with open(config['data_yaml'], 'r') as f:\n",
        "        data_config = yaml.safe_load(f)\n",
        "        print(yaml.dump(data_config, default_flow_style=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa0eaee1",
      "metadata": {
        "id": "fa0eaee1"
      },
      "outputs": [],
      "source": [
        "# Visualize sample images from dataset\n",
        "def visualize_samples(dataset_path, split='train', num_samples=4):\n",
        "    \"\"\"Visualize sample images with their annotations\"\"\"\n",
        "    images_dir = os.path.join(dataset_path, split, 'images')\n",
        "    labels_dir = os.path.join(dataset_path, split, 'labels')\n",
        "    \n",
        "    if not os.path.exists(images_dir):\n",
        "        print(f\"Images directory not found: {images_dir}\")\n",
        "        return\n",
        "    \n",
        "    # Get class names from data.yaml\n",
        "    data_yaml_path = os.path.join(dataset_path, 'data.yaml')\n",
        "    class_names = ['class_0', 'class_1', 'class_2', 'class_3']  # Default\n",
        "    if os.path.exists(data_yaml_path):\n",
        "        with open(data_yaml_path, 'r') as f:\n",
        "            data_config = yaml.safe_load(f)\n",
        "            if 'names' in data_config:\n",
        "                class_names = data_config['names']\n",
        "    \n",
        "    print(f\"Classes: {class_names}\")\n",
        "    \n",
        "    image_files = [f for f in os.listdir(images_dir) if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
        "    num_samples = min(num_samples, len(image_files))\n",
        "    \n",
        "    fig, axes = plt.subplots(2, 2, figsize=(16, 16))\n",
        "    axes = axes.flatten()\n",
        "    \n",
        "    for idx in range(num_samples):\n",
        "        img_file = image_files[idx]\n",
        "        img_path = os.path.join(images_dir, img_file)\n",
        "        label_path = os.path.join(labels_dir, img_file.replace('.jpg', '.txt').replace('.png', '.txt'))\n",
        "        \n",
        "        # Read image\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        h, w = img.shape[:2]\n",
        "        \n",
        "        # Statistics for this image\n",
        "        bbox_stats = {name: 0 for name in class_names}\n",
        "        \n",
        "        # Read and draw bounding boxes\n",
        "        if os.path.exists(label_path):\n",
        "            with open(label_path, 'r') as f:\n",
        "                for line in f.readlines():\n",
        "                    line = line.strip()\n",
        "                    if not line:  # Skip empty lines\n",
        "                        continue\n",
        "                    \n",
        "                    # Split and parse the line\n",
        "                    parts = line.split()\n",
        "                    if len(parts) < 5:  # Need at least class_id + 4 bbox values\n",
        "                        continue\n",
        "                    \n",
        "                    # Extract the first 5 values (class_id, x_center, y_center, width, height)\n",
        "                    class_id = int(float(parts[0]))\n",
        "                    x_center = float(parts[1])\n",
        "                    y_center = float(parts[2])\n",
        "                    width = float(parts[3])\n",
        "                    height = float(parts[4])\n",
        "                    \n",
        "                    # Count this class\n",
        "                    if class_id < len(class_names):\n",
        "                        bbox_stats[class_names[class_id]] += 1\n",
        "                    \n",
        "                    # Validate coordinates are in [0, 1] range\n",
        "                    if not (0 <= x_center <= 1 and 0 <= y_center <= 1 and 0 < width <= 1 and 0 < height <= 1):\n",
        "                        print(f\"Warning: Invalid coordinates in {img_file}: class={class_id}, x={x_center}, y={y_center}, w={width}, h={height}\")\n",
        "                    \n",
        "                    # Convert YOLO format to pixel coordinates\n",
        "                    x1 = int((x_center - width/2) * w)\n",
        "                    y1 = int((y_center - height/2) * h)\n",
        "                    x2 = int((x_center + width/2) * w)\n",
        "                    y2 = int((y_center + height/2) * h)\n",
        "                    \n",
        "                    # Clip coordinates to image boundaries\n",
        "                    x1 = max(0, min(x1, w))\n",
        "                    y1 = max(0, min(y1, h))\n",
        "                    x2 = max(0, min(x2, w))\n",
        "                    y2 = max(0, min(y2, h))\n",
        "                    \n",
        "                    # Different colors and thickness for each class\n",
        "                    colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0)]  # Red, Green, Blue, Yellow\n",
        "                    color = colors[class_id % len(colors)]\n",
        "                    \n",
        "                    # Use thicker lines for smaller objects\n",
        "                    thickness = 3 if width * height < 0.1 else 2\n",
        "                    \n",
        "                    # Draw rectangle\n",
        "                    cv2.rectangle(img, (x1, y1), (x2, y2), color, thickness)\n",
        "                    \n",
        "                    # Add class label\n",
        "                    if class_id < len(class_names):\n",
        "                        label_text = class_names[class_id]\n",
        "                        # Put label above the box\n",
        "                        label_y = max(y1 - 5, 15)\n",
        "                        cv2.putText(img, label_text, (x1, label_y), \n",
        "                                  cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "        \n",
        "        axes[idx].imshow(img)\n",
        "        \n",
        "        # Create title with bbox counts\n",
        "        stats_str = ', '.join([f\"{name}: {count}\" for name, count in bbox_stats.items() if count > 0])\n",
        "        axes[idx].set_title(f'{split.capitalize()} Image {idx+1}\\n{stats_str}', fontsize=10)\n",
        "        axes[idx].axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"\\nTotal images in {split} set: {len(image_files)}\")\n",
        "    print(f\"Class colors: {', '.join([f'{class_names[i]}: {c}' for i, c in enumerate(['Red', 'Green', 'Blue', 'Yellow'])])}\")\n",
        "\n",
        "# Visualize training samples\n",
        "visualize_samples(config['dataset_path'], 'train', num_samples=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "678b407e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inspect a sample annotation file in detail\n",
        "train_labels_dir = os.path.join(config['dataset_path'], 'train', 'labels')\n",
        "label_files = [f for f in os.listdir(train_labels_dir) if f.endswith('.txt')]\n",
        "\n",
        "if label_files:\n",
        "    sample_label = os.path.join(train_labels_dir, label_files[0])\n",
        "    print(f\"Inspecting: {label_files[0]}\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    with open(sample_label, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "        print(f\"Total annotations: {len(lines)}\\n\")\n",
        "        \n",
        "        # Count by class\n",
        "        class_counts = {}\n",
        "        for line in lines:\n",
        "            parts = line.strip().split()\n",
        "            if parts:\n",
        "                class_id = int(float(parts[0]))\n",
        "                class_counts[class_id] = class_counts.get(class_id, 0) + 1\n",
        "        \n",
        "        print(\"Annotations per class:\")\n",
        "        for class_id, count in sorted(class_counts.items()):\n",
        "            print(f\"  Class {class_id}: {count} objects\")\n",
        "        \n",
        "        print(\"\\nFirst 5 annotations:\")\n",
        "        for i, line in enumerate(lines[:5]):\n",
        "            parts = line.strip().split()\n",
        "            if len(parts) >= 5:\n",
        "                print(f\"  {i+1}. Class: {parts[0]}, x_center: {parts[1]}, y_center: {parts[2]}, width: {parts[3]}, height: {parts[4]}\")\n",
        "                \n",
        "                # Check if values are in valid range\n",
        "                x, y, w, h = map(float, parts[1:5])\n",
        "                if not (0 <= x <= 1 and 0 <= y <= 1 and 0 < w <= 1 and 0 < h <= 1):\n",
        "                    print(f\"     WARNING: Values out of range [0, 1]!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc15829c",
      "metadata": {
        "id": "dc15829c"
      },
      "source": [
        "## 6. Model Architecture\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f344553",
      "metadata": {
        "id": "3f344553"
      },
      "outputs": [],
      "source": [
        "# Load YOLOv11 model\n",
        "print(f\"Loading {config['model_name']} model...\")\n",
        "model = YOLO(config['model_name'])\n",
        "\n",
        "# Model summary\n",
        "print(\"\\nModel loaded successfully!\")\n",
        "print(f\"Model type: {type(model)}\")\n",
        "print(f\"Device: {config['device']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6abcebc4",
      "metadata": {
        "id": "6abcebc4"
      },
      "source": [
        "## 7. Loss Function and Optimizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c8cec7a",
      "metadata": {
        "id": "8c8cec7a"
      },
      "outputs": [],
      "source": [
        "# YOLOv11 uses built-in loss functions and optimizer\n",
        "# Loss: Combination of box regression, objectness, and classification loss\n",
        "# Optimizer: Adam (as specified in configuration)\n",
        "# These are handled automatically by the Ultralytics framework\n",
        "print(\"Loss function: YOLO loss (box + objectness + classification)\")\n",
        "print(\"Optimizer: Adam\")\n",
        "print(\"Learning rate schedule: Cosine annealing with warmup\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f4a4f2c",
      "metadata": {
        "id": "6f4a4f2c"
      },
      "source": [
        "## 8. Training and Validation Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a68a0222",
      "metadata": {
        "id": "a68a0222"
      },
      "outputs": [],
      "source": [
        "# YOLOv11 handles training and validation internally\n",
        "# The model.train() method includes:\n",
        "# - Training loop with gradient updates\n",
        "# - Validation after each epoch\n",
        "# - Early stopping based on patience\n",
        "# - Model checkpointing (best and last weights)\n",
        "# - Automatic metric calculation (mAP, precision, recall, F1)\n",
        "print(\"Training and validation are handled by YOLO's built-in training pipeline\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4dff8f92",
      "metadata": {
        "id": "4dff8f92"
      },
      "source": [
        "## 9. Training Loop\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "343f7016",
      "metadata": {
        "id": "343f7016"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "print(\"Starting training...\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "results = model.train(\n",
        "    data=config['data_yaml'],\n",
        "    epochs=config['epochs'],\n",
        "    imgsz=config['img_size'],\n",
        "    batch=config['batch_size'],\n",
        "    device=config['device'],\n",
        "    project=config['project'],\n",
        "    name=config['name'],\n",
        "    patience=config['patience'],\n",
        "    save=True,\n",
        "    plots=True,\n",
        "    verbose=True,\n",
        "    val=True,\n",
        "    # Optimizer settings (Adam as per proposal)\n",
        "    optimizer='Adam',\n",
        "    lr0=0.01,  # Initial learning rate\n",
        "    lrf=0.01,  # Final learning rate\n",
        "    # Augmentation settings\n",
        "    mosaic=1.0,\n",
        "    mixup=0.0,\n",
        "    hsv_h=0.015,  # HSV-Hue augmentation\n",
        "    hsv_s=0.7,    # HSV-Saturation augmentation\n",
        "    hsv_v=0.4,    # HSV-Value augmentation\n",
        "    degrees=0.0,  # Rotation\n",
        "    translate=0.1,\n",
        "    scale=0.5,\n",
        "    fliplr=0.5,   # Horizontal flip\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Training completed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "504eccbd",
      "metadata": {
        "id": "504eccbd"
      },
      "source": [
        "## 10. Plot Training History\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29488e78",
      "metadata": {
        "id": "29488e78"
      },
      "outputs": [],
      "source": [
        "# Display training results\n",
        "print(\"Training Results Summary:\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Get the results directory\n",
        "results_dir = os.path.join(config['project'], config['name'])\n",
        "\n",
        "if os.path.exists(results_dir):\n",
        "    print(f\"\\nResults saved to: {results_dir}\")\n",
        "    \n",
        "    # Display training plots\n",
        "    plots = ['results.png', 'confusion_matrix.png', 'F1_curve.png', 'PR_curve.png', 'P_curve.png', 'R_curve.png']\n",
        "    \n",
        "    fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
        "    axes = axes.flatten()\n",
        "    \n",
        "    for idx, plot_name in enumerate(plots):\n",
        "        plot_path = os.path.join(results_dir, plot_name)\n",
        "        if os.path.exists(plot_path):\n",
        "            img = plt.imread(plot_path)\n",
        "            axes[idx].imshow(img)\n",
        "            axes[idx].set_title(plot_name.replace('.png', '').replace('_', ' ').title())\n",
        "            axes[idx].axis('off')\n",
        "        else:\n",
        "            axes[idx].text(0.5, 0.5, f'{plot_name}\\nNot Available', \n",
        "                          ha='center', va='center', fontsize=12)\n",
        "            axes[idx].axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Display best model metrics\n",
        "    if hasattr(results, 'results_dict'):\n",
        "        print(\"\\nBest Model Metrics:\")\n",
        "        for key, value in results.results_dict.items():\n",
        "            if isinstance(value, (int, float)):\n",
        "                print(f\"  {key}: {value:.4f}\")\n",
        "else:\n",
        "    print(f\"Results directory not found: {results_dir}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a07388e",
      "metadata": {
        "id": "6a07388e"
      },
      "source": [
        "## 11. Save Final Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adce70df",
      "metadata": {
        "id": "adce70df"
      },
      "outputs": [],
      "source": [
        "# Save final results to Google Drive\n",
        "print(\"Saving results to Google Drive...\")\n",
        "\n",
        "# Create save directory\n",
        "os.makedirs(config['save_dir'], exist_ok=True)\n",
        "\n",
        "# Copy best model\n",
        "results_dir = os.path.join(config['project'], config['name'])\n",
        "best_model_path = os.path.join(results_dir, 'weights', 'best.pt')\n",
        "last_model_path = os.path.join(results_dir, 'weights', 'last.pt')\n",
        "\n",
        "if os.path.exists(best_model_path):\n",
        "    shutil.copy(best_model_path, os.path.join(config['save_dir'], 'best.pt'))\n",
        "    print(f\"✓ Saved best model to {config['save_dir']}/best.pt\")\n",
        "    \n",
        "if os.path.exists(last_model_path):\n",
        "    shutil.copy(last_model_path, os.path.join(config['save_dir'], 'last.pt'))\n",
        "    print(f\"✓ Saved last model to {config['save_dir']}/last.pt\")\n",
        "\n",
        "# Copy results plots\n",
        "if os.path.exists(results_dir):\n",
        "    for file in os.listdir(results_dir):\n",
        "        if file.endswith('.png') or file.endswith('.csv'):\n",
        "            src = os.path.join(results_dir, file)\n",
        "            dst = os.path.join(config['save_dir'], file)\n",
        "            shutil.copy(src, dst)\n",
        "    print(f\"✓ Saved plots and results to {config['save_dir']}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"All results saved successfully!\")\n",
        "print(f\"Check Google Drive: {config['save_dir']}\")\n",
        "print(\"=\"*50)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "554fe809",
      "metadata": {},
      "source": [
        "## 12. Test Model on Sample Images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "629fe5ed",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load best model and run inference on test images\n",
        "best_model = YOLO(os.path.join(config['save_dir'], 'best.pt'))\n",
        "\n",
        "# Get test images\n",
        "test_images_dir = os.path.join(config['dataset_path'], 'test', 'images')\n",
        "test_images = [os.path.join(test_images_dir, f) for f in os.listdir(test_images_dir) if f.endswith(('.jpg', '.png', '.jpeg'))][:4]\n",
        "\n",
        "print(f\"Testing on {len(test_images)} sample images...\")\n",
        "\n",
        "# Run inference\n",
        "results = best_model(test_images, conf=0.25, iou=0.45)\n",
        "\n",
        "# Visualize results\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 16))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for idx, (result, img_path) in enumerate(zip(results, test_images)):\n",
        "    # Plot the result\n",
        "    img_with_boxes = result.plot()\n",
        "    \n",
        "    # Convert BGR to RGB for matplotlib\n",
        "    img_rgb = cv2.cvtColor(img_with_boxes, cv2.COLOR_BGR2RGB)\n",
        "    \n",
        "    axes[idx].imshow(img_rgb)\n",
        "    axes[idx].set_title(f'Test Image {idx+1} - Detections: {len(result.boxes)}')\n",
        "    axes[idx].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print detection statistics\n",
        "print(\"\\nDetection Statistics:\")\n",
        "for idx, result in enumerate(results):\n",
        "    print(f\"\\nImage {idx+1}:\")\n",
        "    if len(result.boxes) > 0:\n",
        "        classes = result.boxes.cls.cpu().numpy()\n",
        "        confidences = result.boxes.conf.cpu().numpy()\n",
        "        \n",
        "        # Count detections per class\n",
        "        unique_classes, counts = np.unique(classes, return_counts=True)\n",
        "        class_names = result.names\n",
        "        \n",
        "        for cls, count in zip(unique_classes, counts):\n",
        "            print(f\"  {class_names[int(cls)]}: {count} detections\")\n",
        "        print(f\"  Average confidence: {confidences.mean():.3f}\")\n",
        "    else:\n",
        "        print(\"  No detections\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
