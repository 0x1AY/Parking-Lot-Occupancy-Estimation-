{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "400bb065",
   "metadata": {},
   "source": [
    "## 1. Environment Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d50a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bc3f4b",
   "metadata": {},
   "source": [
    "## 2. Dataset Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac5fbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset paths\n",
    "DATASET_NAME = \"Dataset-V1-multiclass\"\n",
    "DATASET_ROOT = os.path.join(os.getcwd(), DATASET_NAME)\n",
    "\n",
    "# For Google Colab, use environment variable if set\n",
    "if os.getenv('DATASET_ROOT'):\n",
    "    DATASET_ROOT = os.getenv('DATASET_ROOT')\n",
    "    print(f\"Using DATASET_ROOT from environment: {DATASET_ROOT}\")\n",
    "else:\n",
    "    print(f\"Using local DATASET_ROOT: {DATASET_ROOT}\")\n",
    "\n",
    "DATA_YAML = os.path.join(DATASET_ROOT, \"data.yaml\")\n",
    "\n",
    "# Verify dataset exists\n",
    "if os.path.exists(DATA_YAML):\n",
    "    print(f\"âœ… Dataset found: {DATA_YAML}\")\n",
    "    with open(DATA_YAML, 'r') as f:\n",
    "        data_config = yaml.safe_load(f)\n",
    "    print(f\"Classes: {data_config['names']}\")\n",
    "    print(f\"Number of classes: {data_config['nc']}\")\n",
    "else:\n",
    "    print(f\"âŒ Dataset not found at: {DATA_YAML}\")\n",
    "    print(\"Please run tools/create_multiclass_dataset.py first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9c91f0",
   "metadata": {},
   "source": [
    "## 3. Verify Dataset Statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f1b6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count images in each split\n",
    "splits = ['train', 'valid', 'test']\n",
    "dataset_stats = {}\n",
    "\n",
    "for split in splits:\n",
    "    images_dir = os.path.join(DATASET_ROOT, split, 'images')\n",
    "    labels_dir = os.path.join(DATASET_ROOT, split, 'labels')\n",
    "    \n",
    "    if os.path.exists(images_dir):\n",
    "        num_images = len([f for f in os.listdir(images_dir) if f.endswith('.jpg')])\n",
    "        num_labels = len([f for f in os.listdir(labels_dir) if f.endswith('.txt')])\n",
    "        dataset_stats[split] = {'images': num_images, 'labels': num_labels}\n",
    "    else:\n",
    "        dataset_stats[split] = {'images': 0, 'labels': 0}\n",
    "\n",
    "print(\"\\nðŸ“Š Dataset Statistics:\")\n",
    "print(\"=\"*50)\n",
    "for split, stats in dataset_stats.items():\n",
    "    print(f\"{split.capitalize():8s}: {stats['images']:3d} images, {stats['labels']:3d} labels\")\n",
    "print(\"=\"*50)\n",
    "total_images = sum(s['images'] for s in dataset_stats.values())\n",
    "print(f\"Total:     {total_images:3d} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96036831",
   "metadata": {},
   "source": [
    "## 4. Visualize Sample Annotations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fe77cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_annotations(image_path, label_path, class_names):\n",
    "    \"\"\"\n",
    "    Visualize YOLO format annotations on image using matplotlib.\n",
    "    \n",
    "    Args:\n",
    "        image_path: Path to image file\n",
    "        label_path: Path to YOLO format label file\n",
    "        class_names: Dictionary mapping class IDs to names\n",
    "    \"\"\"\n",
    "    # Read image\n",
    "    img = cv2.imread(str(image_path))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    h, w = img.shape[:2]\n",
    "    \n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(1, figsize=(12, 8))\n",
    "    ax.imshow(img)\n",
    "    \n",
    "    # Color map for classes\n",
    "    colors = {\n",
    "        0: '#FF0000',  # car - red\n",
    "        1: '#00FF00',  # lot_boundary - green\n",
    "        3: '#0000FF',  # stall - blue\n",
    "    }\n",
    "    \n",
    "    # Read and draw annotations\n",
    "    if os.path.exists(label_path):\n",
    "        with open(label_path, 'r') as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) >= 5:\n",
    "                    class_id = int(parts[0])\n",
    "                    x_center, y_center, bbox_w, bbox_h = map(float, parts[1:5])\n",
    "                    \n",
    "                    # Convert YOLO format to pixel coordinates\n",
    "                    x_center_px = x_center * w\n",
    "                    y_center_px = y_center * h\n",
    "                    bbox_w_px = bbox_w * w\n",
    "                    bbox_h_px = bbox_h * h\n",
    "                    \n",
    "                    # Calculate corner coordinates\n",
    "                    x1 = x_center_px - bbox_w_px / 2\n",
    "                    y1 = y_center_px - bbox_h_px / 2\n",
    "                    \n",
    "                    # Draw rectangle\n",
    "                    color = colors.get(class_id, '#FFFFFF')\n",
    "                    rect = plt.Rectangle((x1, y1), bbox_w_px, bbox_h_px,\n",
    "                                        fill=False, edgecolor=color, linewidth=2)\n",
    "                    ax.add_patch(rect)\n",
    "                    \n",
    "                    # Add label\n",
    "                    class_name = class_names.get(class_id, f'class_{class_id}')\n",
    "                    ax.text(x1, y1 - 5, class_name, \n",
    "                           color=color, fontsize=10, weight='bold',\n",
    "                           bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.7))\n",
    "    \n",
    "    ax.axis('off')\n",
    "    plt.title(f\"Image: {os.path.basename(image_path)}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Visualize a sample from train set\n",
    "train_images = Path(DATASET_ROOT) / 'train' / 'images'\n",
    "train_labels = Path(DATASET_ROOT) / 'train' / 'labels'\n",
    "\n",
    "sample_images = list(train_images.glob('*.jpg'))[:3]  # First 3 images\n",
    "\n",
    "for img_path in sample_images:\n",
    "    label_path = train_labels / (img_path.stem + '.txt')\n",
    "    visualize_annotations(img_path, label_path, data_config['names'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc10c09a",
   "metadata": {},
   "source": [
    "## 5. Training Configuration\n",
    "\n",
    "Multi-class training with all classes enabled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdebda3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "config = {\n",
    "    # Model\n",
    "    'model': 'yolo11m.pt',  # YOLOv11 medium pretrained\n",
    "    \n",
    "    # Training parameters\n",
    "    'epochs': 100,\n",
    "    'batch': 16,\n",
    "    'imgsz': 640,\n",
    "    'patience': 20,  # Early stopping\n",
    "    'workers': 8,\n",
    "    'device': 0,  # GPU 0, use 'cpu' for CPU training\n",
    "    \n",
    "    # Optimizer\n",
    "    'optimizer': 'AdamW',\n",
    "    'lr0': 0.00125,  # Initial learning rate\n",
    "    'lrf': 0.01,     # Final learning rate factor\n",
    "    'momentum': 0.937,\n",
    "    'weight_decay': 0.0005,\n",
    "    \n",
    "    # Data augmentation\n",
    "    'hsv_h': 0.015,  # HSV-Hue augmentation\n",
    "    'hsv_s': 0.7,    # HSV-Saturation augmentation\n",
    "    'hsv_v': 0.4,    # HSV-Value augmentation\n",
    "    'degrees': 10.0,  # Rotation degrees\n",
    "    'translate': 0.1,  # Translation\n",
    "    'scale': 0.5,     # Scaling\n",
    "    'shear': 0.0,     # Shear\n",
    "    'perspective': 0.0,  # Perspective\n",
    "    'flipud': 0.0,    # Flip up-down\n",
    "    'fliplr': 0.5,    # Flip left-right\n",
    "    'mosaic': 1.0,    # Mosaic augmentation\n",
    "    'mixup': 0.0,     # Mixup augmentation\n",
    "    \n",
    "    # Output\n",
    "    'project': 'parking_runs',\n",
    "    'name': 'yolo11m_multiclass',\n",
    "    'exist_ok': True,\n",
    "    'save': True,\n",
    "    'save_period': 10,  # Save checkpoint every 10 epochs\n",
    "}\n",
    "\n",
    "print(\"Training Configuration:\")\n",
    "print(\"=\"*60)\n",
    "for key, value in config.items():\n",
    "    print(f\"{key:20s}: {value}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87130ef5",
   "metadata": {},
   "source": [
    "## 6. Train Multi-Class Model\n",
    "\n",
    "Training on car (0), lot_boundary (1), and stall (3) classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cdd417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = YOLO(config['model'])\n",
    "\n",
    "# Train with all configuration parameters\n",
    "results = model.train(\n",
    "    data=DATA_YAML,\n",
    "    epochs=config['epochs'],\n",
    "    batch=config['batch'],\n",
    "    imgsz=config['imgsz'],\n",
    "    patience=config['patience'],\n",
    "    workers=config['workers'],\n",
    "    device=config['device'],\n",
    "    optimizer=config['optimizer'],\n",
    "    lr0=config['lr0'],\n",
    "    lrf=config['lrf'],\n",
    "    momentum=config['momentum'],\n",
    "    weight_decay=config['weight_decay'],\n",
    "    hsv_h=config['hsv_h'],\n",
    "    hsv_s=config['hsv_s'],\n",
    "    hsv_v=config['hsv_v'],\n",
    "    degrees=config['degrees'],\n",
    "    translate=config['translate'],\n",
    "    scale=config['scale'],\n",
    "    shear=config['shear'],\n",
    "    perspective=config['perspective'],\n",
    "    flipud=config['flipud'],\n",
    "    fliplr=config['fliplr'],\n",
    "    mosaic=config['mosaic'],\n",
    "    mixup=config['mixup'],\n",
    "    project=config['project'],\n",
    "    name=config['name'],\n",
    "    exist_ok=config['exist_ok'],\n",
    "    save=config['save'],\n",
    "    save_period=config['save_period'],\n",
    ")\n",
    "\n",
    "print(\"\\nâœ… Training completed!\")\n",
    "print(f\"Best model saved at: {results.save_dir}/weights/best.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3bf528",
   "metadata": {},
   "source": [
    "## 7. Visualize Training Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ae10a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results plot\n",
    "results_img = plt.imread(f\"{config['project']}/{config['name']}/results.png\")\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.imshow(results_img)\n",
    "plt.axis('off')\n",
    "plt.title('Training Results')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d58832",
   "metadata": {},
   "source": [
    "## 8. Load Best Model for Inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b152fc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "best_model_path = f\"{config['project']}/{config['name']}/weights/best.pt\"\n",
    "model_best = YOLO(best_model_path)\n",
    "\n",
    "print(f\"âœ… Loaded best model from: {best_model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a254ba8c",
   "metadata": {},
   "source": [
    "## 9. Validation Metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf88c3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run validation\n",
    "metrics = model_best.val(data=DATA_YAML)\n",
    "\n",
    "print(\"\\nðŸ“Š Validation Metrics:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"mAP50:     {metrics.box.map50:.4f}\")\n",
    "print(f\"mAP50-95:  {metrics.box.map:.4f}\")\n",
    "print(f\"Precision: {metrics.box.mp:.4f}\")\n",
    "print(f\"Recall:    {metrics.box.mr:.4f}\")\n",
    "print(\"\\nPer-class mAP50:\")\n",
    "for i, (class_name, map50) in enumerate(zip(data_config['names'].values(), metrics.box.maps)):\n",
    "    print(f\"  {class_name:15s}: {map50:.4f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75334cdf",
   "metadata": {},
   "source": [
    "## 10. Confusion Matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13096d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display confusion matrix\n",
    "cm_img = plt.imread(f\"{config['project']}/{config['name']}/confusion_matrix.png\")\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.imshow(cm_img)\n",
    "plt.axis('off')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023d9471",
   "metadata": {},
   "source": [
    "## 11. Test Predictions on Sample Images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a15bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sample test images\n",
    "test_images_dir = Path(DATASET_ROOT) / 'test' / 'images'\n",
    "test_images = list(test_images_dir.glob('*.jpg'))[:5]  # First 5 test images\n",
    "\n",
    "# Run predictions\n",
    "for img_path in test_images:\n",
    "    results = model_best.predict(source=str(img_path), save=False, conf=0.25)\n",
    "    \n",
    "    # Plot results\n",
    "    result = results[0]\n",
    "    img_with_boxes = result.plot()\n",
    "    img_rgb = cv2.cvtColor(img_with_boxes, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.imshow(img_rgb)\n",
    "    plt.axis('off')\n",
    "    plt.title(f'Predictions: {img_path.name}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print detection summary\n",
    "    print(f\"\\nDetections in {img_path.name}:\")\n",
    "    if len(result.boxes) > 0:\n",
    "        for box in result.boxes:\n",
    "            cls_id = int(box.cls[0])\n",
    "            conf = float(box.conf[0])\n",
    "            cls_name = data_config['names'][cls_id]\n",
    "            print(f\"  {cls_name}: {conf:.3f}\")\n",
    "    else:\n",
    "        print(\"  No detections\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9252e3d0",
   "metadata": {},
   "source": [
    "## 12. Export Model (Optional)\n",
    "\n",
    "Export to ONNX, TorchScript, or other formats for deployment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7076bb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to ONNX (optional)\n",
    "# model_best.export(format='onnx', dynamic=True, simplify=True)\n",
    "# print(\"âœ… Model exported to ONNX format\")\n",
    "\n",
    "print(\"To export model, uncomment the code above and run this cell\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0519e4a9",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**Next Steps:**\n",
    "\n",
    "1. Use this trained model to detect cars and stalls in unlabeled images\n",
    "2. Create occupancy detection pipeline using IoU matching\n",
    "3. Implement in `occupancy.ipynb` for real-world deployment\n",
    "\n",
    "**Model outputs:**\n",
    "\n",
    "- Best weights: `parking_runs/yolo11m_multiclass/weights/best.pt`\n",
    "- Training results: `parking_runs/yolo11m_multiclass/results.png`\n",
    "- Confusion matrix: `parking_runs/yolo11m_multiclass/confusion_matrix.png`\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
